"""
Script to adapt code from cloned repositories
Extracts and adapts useful code from Magnum-Opus and documentClassification
"""

import os
import shutil
from pathlib import Path


def analyze_repositories():
    """Analyze what we have from the cloned repositories"""
    print("="*60)
    print("ğŸ“š ANALYZING CLONED REPOSITORIES")
    print("="*60)
    
    # Magnum-Opus
    print("\nğŸ” Magnum-Opus Repository:")
    magnum_path = Path("temp_magnum")
    if magnum_path.exists():
        print(f"   âœ… Found at: {magnum_path.absolute()}")
        
        # Check for key files
        train2 = magnum_path / "model" / "train2.py"
        main = magnum_path / "main.py"
        opclass = magnum_path / "opclass.py"
        
        print(f"   ğŸ“„ train2.py: {'âœ…' if train2.exists() else 'âŒ'}")
        print(f"   ğŸ“„ main.py: {'âœ…' if main.exists() else 'âŒ'}")
        print(f"   ğŸ“„ opclass.py: {'âœ…' if opclass.exists() else 'âŒ'}")
        
        # Check for data directories
        data_dirs = list(magnum_path.glob("**/train*")) + list(magnum_path.glob("**/data*"))
        if data_dirs:
            print(f"   ğŸ“ Data directories found: {len(data_dirs)}")
            for d in data_dirs[:3]:
                print(f"      - {d.relative_to(magnum_path)}")
    else:
        print("   âŒ Not found")
    
    # documentClassification
    print("\nğŸ” documentClassification Repository:")
    doc_path = Path("temp_doc")
    if doc_path.exists():
        print(f"   âœ… Found at: {doc_path.absolute()}")
        
        # Check for notebooks
        notebooks = list(doc_path.glob("*.ipynb"))
        print(f"   ğŸ““ Notebooks found: {len(notebooks)}")
        for nb in notebooks:
            print(f"      - {nb.name}")
        
        # Check for data
        files_dir = doc_path / "Files"
        if files_dir.exists():
            files = list(files_dir.glob("*"))
            print(f"   ğŸ“ Files directory: {len(files)} files")
            for f in files[:3]:
                print(f"      - {f.name} ({f.stat().st_size / 1024 / 1024:.1f} MB)")
    else:
        print("   âŒ Not found")
    
    print("\n" + "="*60)


def extract_useful_code():
    """Extract and adapt useful code from repositories"""
    print("\nğŸ“‹ EXTRACTION SUMMARY:")
    print("="*60)
    
    print("\nâœ… From Magnum-Opus (temp_magnum/):")
    print("   - train2.py: VGG16-based training script")
    print("   - opclass.py: Classification class wrapper")
    print("   - main.py: Example usage")
    print("\n   ğŸ’¡ Key insights:")
    print("      â€¢ Uses VGG16 with frozen layers (except last 4)")
    print("      â€¢ Sequential model with Flatten + Dense(1024) + Dropout(0.5)")
    print("      â€¢ 3-class classification (we need 4: Aadhaar, PAN, Fake, Other)")
    print("      â€¢ Uses ImageDataGenerator for augmentation")
    
    print("\nâœ… From documentClassification (temp_doc/):")
    print("   - CNN_OCR_model.ipynb: CNN model with OCR")
    print("   - Files/: Sample PDF and output")
    print("\n   ğŸ’¡ Key insights:")
    print("      â€¢ Custom CNN architecture")
    print("      â€¢ PDF splitting capability")
    print("      â€¢ OCR integration")
    
    print("\nğŸ“ Our Implementation:")
    print("   âœ… Already adapted VGG16 backbone (similar to train2.py)")
    print("   âœ… Already created custom CNN (inspired by documentClassification)")
    print("   âœ… Added Sequential CNN (from paper specification)")
    print("   âœ… Combined into ensemble model")
    print("   âœ… Added PDF support (PyMuPDF)")
    print("   âœ… Added OCR utilities")
    
    print("\n" + "="*60)


def create_adaptation_notes():
    """Create notes about what was adapted"""
    notes = """
# Repository Adaptation Notes

## Magnum-Opus Repository
**Location**: `temp_magnum/`

### Key Files:
- `model/train2.py`: VGG16-based training script
- `opclass.py`: Classification wrapper class
- `main.py`: Example usage

### What We Adapted:
1. **VGG16 Architecture**: 
   - Original: Sequential model with Flatten + Dense(1024) + Dropout(0.5) + Dense(3)
   - Our version: Functional API with GlobalAveragePooling + Dense(512) + Dense(256) + dual outputs
   - Enhanced: Added authenticity head for fake detection

2. **Training Approach**:
   - Original: Freezes all layers except last 4
   - Our version: Freezes all base layers initially (can be fine-tuned)
   - Enhanced: Added ensemble approach with 3 backbones

3. **Class Count**:
   - Original: 3 classes
   - Our version: 4 classes (Aadhaar, PAN, Fake, Other)

## documentClassification Repository
**Location**: `temp_doc/`

### Key Files:
- `CNN_OCR_model.ipynb`: CNN model with OCR integration
- `Files/`: Sample PDF and output files

### What We Adapted:
1. **Custom CNN Architecture**:
   - Original: Custom CNN from notebook
   - Our version: 5-layer CNN with batch normalization
   - Enhanced: Added to ensemble, dual outputs

2. **PDF Processing**:
   - Original: PDF splitting mentioned in README
   - Our version: Implemented with PyMuPDF in Streamlit app
   - Enhanced: Full PDF to image conversion

3. **OCR Integration**:
   - Original: OCR steps in notebook
   - Our version: Complete OCR utilities with Tesseract
   - Enhanced: Aadhaar/PAN number extraction and validation

## Improvements Made:
1. âœ… Ensemble model combining 3 backbones
2. âœ… Dual output (classification + authenticity)
3. âœ… Fake detection module
4. âœ… Complete OCR pipeline
5. âœ… Streamlit web interface
6. âœ… PDF support
7. âœ… Comprehensive training script
8. âœ… Evaluation metrics and visualization

## Next Steps:
- If you want to use datasets from these repos, check:
  - `temp_magnum/` for any data folders
  - `temp_doc/Files/` for sample documents
  - Consider extracting images if available
"""
    
    with open("REPOSITORY_ADAPTATION_NOTES.md", "w") as f:
        f.write(notes)
    
    print("\nâœ… Created REPOSITORY_ADAPTATION_NOTES.md")


if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸ”„ ADAPTING CODE FROM CLONED REPOSITORIES")
    print("="*60)
    
    analyze_repositories()
    extract_useful_code()
    create_adaptation_notes()
    
    print("\nâœ… Adaptation analysis complete!")
    print("\nğŸ’¡ Note: Our implementation already incorporates the key concepts")
    print("   from both repositories. The cloned repos are available in")
    print("   temp_magnum/ and temp_doc/ for reference.")
    print("\nğŸ“– See REPOSITORY_ADAPTATION_NOTES.md for details.")

